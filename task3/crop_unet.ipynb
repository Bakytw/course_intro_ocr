{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms as tr\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = Path().absolute().parent.parent / \"CourseOCRTask3/Train\"\n",
    "TEST_DATASET_PATH = Path().absolute().parent.parent / \"CourseOCRTask3/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fc272e4092ccb147a31e66bc1d10fbfb.png</td>\n",
       "      <td>3601514743345</td>\n",
       "      <td>538</td>\n",
       "      <td>248</td>\n",
       "      <td>1590</td>\n",
       "      <td>225</td>\n",
       "      <td>1597</td>\n",
       "      <td>663</td>\n",
       "      <td>532</td>\n",
       "      <td>676</td>\n",
       "      <td>1010101111000110101100110111001011001101000110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8cde8cb1b54bca37c9347baf74157d22.png</td>\n",
       "      <td>7000001062307</td>\n",
       "      <td>372</td>\n",
       "      <td>433</td>\n",
       "      <td>360</td>\n",
       "      <td>1289</td>\n",
       "      <td>124</td>\n",
       "      <td>1293</td>\n",
       "      <td>147</td>\n",
       "      <td>431</td>\n",
       "      <td>1010001101010011100011010100111000110101100110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70a9be0887eae17eabd70c8e607f963f.png</td>\n",
       "      <td>2250001407126</td>\n",
       "      <td>408</td>\n",
       "      <td>230</td>\n",
       "      <td>1224</td>\n",
       "      <td>229</td>\n",
       "      <td>1224</td>\n",
       "      <td>688</td>\n",
       "      <td>414</td>\n",
       "      <td>683</td>\n",
       "      <td>1010010011011000101001110100111000110101100110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a029e49dff95a15d2cd396d8f62220c8.png</td>\n",
       "      <td>10101427156</td>\n",
       "      <td>335</td>\n",
       "      <td>149</td>\n",
       "      <td>1005</td>\n",
       "      <td>155</td>\n",
       "      <td>1005</td>\n",
       "      <td>438</td>\n",
       "      <td>335</td>\n",
       "      <td>447</td>\n",
       "      <td>1010001101001100100011010011001000110100110010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82ff01909b6d215170dfc26c7be43074.png</td>\n",
       "      <td>2400745402226</td>\n",
       "      <td>469</td>\n",
       "      <td>237</td>\n",
       "      <td>1388</td>\n",
       "      <td>260</td>\n",
       "      <td>1392</td>\n",
       "      <td>712</td>\n",
       "      <td>464</td>\n",
       "      <td>696</td>\n",
       "      <td>1010100011000110101001110010001010001101110010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>c532771808e76e333ba9e959853886f3.png</td>\n",
       "      <td>4823077510083</td>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>622</td>\n",
       "      <td>53</td>\n",
       "      <td>622</td>\n",
       "      <td>202</td>\n",
       "      <td>87</td>\n",
       "      <td>202</td>\n",
       "      <td>1010110111001101101111010001101001000100100010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8195</th>\n",
       "      <td>186338ad8f3ff17b6082c023f24563f0.png</td>\n",
       "      <td>4823077505386</td>\n",
       "      <td>109</td>\n",
       "      <td>44</td>\n",
       "      <td>664</td>\n",
       "      <td>55</td>\n",
       "      <td>668</td>\n",
       "      <td>206</td>\n",
       "      <td>107</td>\n",
       "      <td>192</td>\n",
       "      <td>1010110111001101101111010001101001000100100010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8196</th>\n",
       "      <td>5bac8f6c9bd5e99f92eb396442974c4e.png</td>\n",
       "      <td>4823077505492</td>\n",
       "      <td>121</td>\n",
       "      <td>27</td>\n",
       "      <td>704</td>\n",
       "      <td>13</td>\n",
       "      <td>704</td>\n",
       "      <td>168</td>\n",
       "      <td>120</td>\n",
       "      <td>187</td>\n",
       "      <td>1010110111001101101111010001101001000100100010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>6247db3e424148a859ebf2180f1dcb6f.png</td>\n",
       "      <td>2010000019696</td>\n",
       "      <td>158</td>\n",
       "      <td>81</td>\n",
       "      <td>165</td>\n",
       "      <td>518</td>\n",
       "      <td>62</td>\n",
       "      <td>521</td>\n",
       "      <td>55</td>\n",
       "      <td>82</td>\n",
       "      <td>1010001101001100101001110100111000110101001110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8198</th>\n",
       "      <td>82d22dc68401a5b173158ae7252b0ab3.png</td>\n",
       "      <td>8691190544256</td>\n",
       "      <td>21</td>\n",
       "      <td>695</td>\n",
       "      <td>32</td>\n",
       "      <td>83</td>\n",
       "      <td>188</td>\n",
       "      <td>83</td>\n",
       "      <td>177</td>\n",
       "      <td>695</td>\n",
       "      <td>1010101111001011100110010110011001011100011010...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8199 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0              1    2    3     4   \\\n",
       "0     fc272e4092ccb147a31e66bc1d10fbfb.png  3601514743345  538  248  1590   \n",
       "1     8cde8cb1b54bca37c9347baf74157d22.png  7000001062307  372  433   360   \n",
       "2     70a9be0887eae17eabd70c8e607f963f.png  2250001407126  408  230  1224   \n",
       "3     a029e49dff95a15d2cd396d8f62220c8.png    10101427156  335  149  1005   \n",
       "4     82ff01909b6d215170dfc26c7be43074.png  2400745402226  469  237  1388   \n",
       "...                                    ...            ...  ...  ...   ...   \n",
       "8194  c532771808e76e333ba9e959853886f3.png  4823077510083   86   54   622   \n",
       "8195  186338ad8f3ff17b6082c023f24563f0.png  4823077505386  109   44   664   \n",
       "8196  5bac8f6c9bd5e99f92eb396442974c4e.png  4823077505492  121   27   704   \n",
       "8197  6247db3e424148a859ebf2180f1dcb6f.png  2010000019696  158   81   165   \n",
       "8198  82d22dc68401a5b173158ae7252b0ab3.png  8691190544256   21  695    32   \n",
       "\n",
       "        5     6     7    8    9   \\\n",
       "0      225  1597   663  532  676   \n",
       "1     1289   124  1293  147  431   \n",
       "2      229  1224   688  414  683   \n",
       "3      155  1005   438  335  447   \n",
       "4      260  1392   712  464  696   \n",
       "...    ...   ...   ...  ...  ...   \n",
       "8194    53   622   202   87  202   \n",
       "8195    55   668   206  107  192   \n",
       "8196    13   704   168  120  187   \n",
       "8197   518    62   521   55   82   \n",
       "8198    83   188    83  177  695   \n",
       "\n",
       "                                                     10  \n",
       "0     1010101111000110101100110111001011001101000110...  \n",
       "1     1010001101010011100011010100111000110101100110...  \n",
       "2     1010010011011000101001110100111000110101100110...  \n",
       "3     1010001101001100100011010011001000110100110010...  \n",
       "4     1010100011000110101001110010001010001101110010...  \n",
       "...                                                 ...  \n",
       "8194  1010110111001101101111010001101001000100100010...  \n",
       "8195  1010110111001101101111010001101001000100100010...  \n",
       "8196  1010110111001101101111010001101001000100100010...  \n",
       "8197  1010001101001100101001110100111000110101001110...  \n",
       "8198  1010101111001011100110010110011001011100011010...  \n",
       "\n",
       "[8199 rows x 11 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_DATASET_PATH / 'markup.csv', encoding='utf-16', header=None)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tr.Compose([\n",
    "            tr.ToTensor(),\n",
    "            tr.Resize((128, 128))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarcodeDataset(Dataset):\n",
    "    def __init__(self, df, path):\n",
    "        self.items = []\n",
    "        for item in tqdm(df.itertuples(index=False)):\n",
    "            try:\n",
    "                x = np.array(Image.open(path / 'Images' / item[0])) / 255.\n",
    "                y = cv2.fillConvexPoly(np.zeros(x.shape[:2]), np.array(item[2:10]).reshape(-1, 2), 1)\n",
    "                y = np.expand_dims(y, axis=-1)\n",
    "                self.items.append((transform(x).float(), transform(y).float()))\n",
    "            except Exception as exc:\n",
    "                print(exc)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.items[idx]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 25.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3510it [09:01,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\bakyt\\\\ml\\\\CourseOCRTask3\\\\Train\\\\Images\\\\cd593cabcf1886a3cc0126491be6c4bc.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6559it [16:33,  6.60it/s]\n",
      "1640it [03:57,  6.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BarcodeDataset(train_df, TRAIN_DATASET_PATH)\n",
    "valid_dataset = BarcodeDataset(val_df, TRAIN_DATASET_PATH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Воспользуемся UNet для сегментации изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.encoder1 = self.conv_block(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self.conv_block(1024, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self.conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self.conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = self.conv_block(128, 64)\n",
    "\n",
    "        self.outconv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "        \n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "        \n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((enc4, dec4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((enc3, dec3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((enc2, dec2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((enc1, dec1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        out = self.outconv(dec1)\n",
    "        return out\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred_flat = y_pred.view(-1)\n",
    "        y_true_flat = y_true.view(-1)\n",
    "        intersection = torch.sum(y_true_flat * y_pred_flat)\n",
    "        dice_coefficient = (2. * intersection + self.smooth) / (torch.sum(y_true_flat) + torch.sum(y_pred_flat) + self.smooth)\n",
    "        return 1 - dice_coefficient\n",
    "\n",
    "unet_model = UNet(in_channels=3, out_channels=1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCornerIdentifier(pl.LightningModule):\n",
    "    def __init__(self, model, optimizer, loss_fn):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.model(inputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        loss = self.loss_fn(outputs, targets)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.model(inputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        loss = self.loss_fn(outputs, targets)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "def train(model, optim, loss_fn, epochs, train_loader, val_loader):\n",
    "    model = LitCornerIdentifier(model, optim, loss_fn)\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=2,\n",
    "        mode='min'\n",
    "    )\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"Unet\")\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,\n",
    "        max_epochs=epochs,\n",
    "        callbacks=[early_stop_callback]\n",
    "    )\n",
    "    trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type     | Params\n",
      "-------------------------------------\n",
      "0 | model   | UNet     | 31.0 M\n",
      "1 | loss_fn | DiceLoss | 0     \n",
      "-------------------------------------\n",
      "31.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 M    Total params\n",
      "124.174   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bakyt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\bakyt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1639/1639 [02:33<00:00, 10.66it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1639/1639 [02:36<00:00, 10.48it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "train(unet_model, torch.optim.Adam(unet_model.parameters()), DiceLoss(), 10, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17316), started 3:39:22 ago. (Use '!kill 17316' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-38c2d0e5aff97ec7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-38c2d0e5aff97ec7\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Протестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 86/101 [00:33<00:05,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file 'C:\\\\Users\\\\bakyt\\\\ml\\\\CourseOCRTask3\\\\Test\\\\Images\\\\desktop.ini'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:38<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "def corners_frame(file, prediction):\n",
    "    mask = (torch.sigmoid(prediction).cpu().detach().numpy() > 0.5).astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    return pd.DataFrame([[file, '-', x, y + h, x, y, x + w, y, x + w, y + h, '-']])\n",
    "\n",
    "def load_image(file):\n",
    "    try:\n",
    "        img = np.array(Image.open(TEST_DATASET_PATH / 'Images' / file)) / 255.\n",
    "        return img\n",
    "    except Exception as exc:\n",
    "        print(exc)\n",
    "        return None\n",
    "\n",
    "\n",
    "test_result = []\n",
    "for file in tqdm(os.listdir(TEST_DATASET_PATH / 'Images')):\n",
    "    img = load_image(file)\n",
    "    if img is not None:\n",
    "        output = unet_model(transform(img).unsqueeze(0).float())\n",
    "        output = tr.Resize(img.shape[:2])(output).squeeze()\n",
    "        test_result.append(corners_frame(file, output))\n",
    "\n",
    "test_result = pd.concat(test_result, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.to_csv('answer.csv', header=False, index=False, encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking answer (c:\\Users\\bakyt\\ml\\course_intro_ocr\\task3\\answer.csv) against markup(c:\\Users\\bakyt\\ml\\course_intro_ocr\\task3\\markup.csv)\n",
      "recognition_accuracy=0.0\n",
      "detection_result=0.99\n",
      "score=0.99\n"
     ]
    }
   ],
   "source": [
    "from course_intro_ocr_t3.evaluate import main\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
